{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "N431a_Auto_New.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10OXb-oNKVzO"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 3 / Assignment 1*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "케라스를 이용한 바이너리 이미지 분류 모델에 3가지 CNN 모델을 적용하여 보는 과제입니다. <br/>\n",
        "\n",
        "- [데이터 다운로드](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/datasets/mountainForest.zip)\n",
        "\n",
        "산의 이미지(./data/mountin/*)와 숲의 이미지(./data/forest/*)를 분류하는 문제입니다. <br/>\n",
        "산을 Positive (1)로, 숲 이미지를 Negative(0)로 레이블링 하여줍니다.\n",
        "\n",
        "클래스당 약 350개의 이미지로 이루어져 있는데요.<br/>\n",
        "표본이 작다는 점을 감안하면 현실적으로 어려운 문제입니다.\n",
        "\n",
        "하지만 이번 과제에서는 해당 데이터에 여러 가지 모델을 적용해보는는 것에 중점을 두어 봅시다. <br/>\n",
        "과제를 통해 이미지 분류에 적용할 수 있는 여러 모델을 알아보고 서로를 비교하는 데 익숙해져 보면 좋겠죠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Ng0p_35yrh"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI3qR2nVKVzT"
      },
      "source": [
        "## Part 1 : Pre-trained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXXsDSZvriLL"
      },
      "source": [
        "Keras에서 제공하는 pre-trained 모델인 ResNet50을 불러와서 사용해봅니다. [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1)은 50 개의 layer를 가진  CNN기반의 모델입니다. <br/>\n",
        "이미지를 [1000 개의 클래스로](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt)를 분류하는 모델인데요. 우리가 풀어야 할 과제는 2가지 이므로 마지막 출력단을 변경해서 사용해 볼 수 있습니다.\n",
        "\n",
        "\n",
        "`ResNet50`을 불러올 때, **`include_top=False`** 로 하면, 기존 1000가지 클래스로의 분류 문제를 풀 수 있는 ResNet 모델에서 Fully Connected layer 부분을 제거해주는 역할을 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHZAR2pnyD65"
      },
      "source": [
        "```python\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D()\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Km6oGLqP0z"
      },
      "source": [
        "아래 부분은 ResNet50 레이어들의 파라미터를 학습하지 않도록 설정합니다. <br/>\n",
        "이렇게 설정된 매개 변수는 역전파를 통해 오차 정보가 전파 되더라도 파라미터가 업데이트 되지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8Kn76NkyIgG"
      },
      "source": [
        "```python\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qg5wDPPqV0P"
      },
      "source": [
        "모델에 추가로 **`Fully-conneted layer(Dense)`** 를 추가해야 합니다. <br/>\n",
        "사전 학습 모델을 불러오면서 최상위 레이어인 **`Fully-conneted layer`** 를 제거했기 때문이지요.\n",
        "\n",
        "새로 추가하는 **`Fully-conneted layer`** 에서는 목적인 이진 분류에 맞게 출력층을 설계하여 주어야 합니다. <br/> **`GlobalAveragePooling2D`** 레이어는 마지막 컨벌루션 레이어 출력(2 차원) 각각의 평균을 취해주어 **`Dense`** 층에 들어갈 수 있도록 해줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfCWu5bJyNoW"
      },
      "source": [
        "```python\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x) # 출력층을 설계합니다.\n",
        "model = Model(resnet.input, predictions)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvJd3ItAKVzU"
      },
      "source": [
        "### Load in Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTcetvpqwO5X"
      },
      "source": [
        "[Keras ImageDataGenerator](https://keras.io/api/preprocessing/image/) 를 참고하여 데이터를 불러옵니다. <br/>\n",
        "위 링크뿐만 아니라 구글링을 통해 ImageDataGenerator 라이브러리에 대한 여러 예제를 조사하고 참고해보세요. \n",
        "\n",
        "Notebook을 여러분의 Google Drive에 Mount 한 후에 이미지를 불러오도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4c0M58cKVzW",
        "outputId": "61d0711d-2649-4435-9940-bd2cb649a6b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzezBMBKVza"
      },
      "source": [
        "### Instatiate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0i14sSCKVzb",
        "outputId": "0e48d148-41c1-437d-9276-6bddb793841f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 533 files belonging to 2 classes.\n",
            "Found 195 files belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<BatchDataset shapes: ((None, 256, 256, 3), (None, 1)), types: (tf.float32, tf.float32)>,\n",
              " <BatchDataset shapes: ((None, 256, 256, 3), (None, 1)), types: (tf.float32, tf.float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPIAXLRKaB9A"
      },
      "source": [
        "train = '/content/drive/MyDrive/train'\n",
        "validation = '/content/drive/MyDrive/validation'\n",
        "\n",
        "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    class_names=[\"forest\", \"mountain\"],\n",
        "    seed=6,\n",
        ")\n",
        "\n",
        "validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    validation,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    class_names=[\"forest\", \"mountain\"],\n",
        "    seed=6,\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtQX3ALdKVzf"
      },
      "source": [
        "### Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPEt-wwuKVzg",
        "outputId": "710ebf0b-f627-4790-8550-e7489ba4bdd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "resnet = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(resnet.input, predictions)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjBDRtCw55Sb"
      },
      "source": [
        "## Part 2 : Custom CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gpEjsFpKVzj"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "이 단계에서는 Keras를 사용하여 자신 만의 CNN을 작성하고 훈련합니다. <br/>\n",
        "네트워크에 적어도 하나의 Conv 레이어와 pooling 레이어가있는 아키텍처를 만들어 사용해 보세요. <br/> 아래는 여러분이 참고할 수 있도록 표시한 결과이며 여러분의 마음대로 설계하여도 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St--__KE0mN5"
      },
      "source": [
        "### Make a Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgwLFkhUKVzj",
        "outputId": "df3a853a-3bad-4960-8cc1-6d743a1f724a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, ReLU, BatchNormalization, Dropout\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(32, (3,3), padding='same', input_shape=(256,256,3)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(ReLU())\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(MaxPooling2D((2,2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(64))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(ReLU())\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256, 256, 32)      128       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 524288)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                33554496  \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 33,555,841\n",
            "Trainable params: 33,555,649\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS18U9mP0f2F"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5NrX3K9KVzm"
      },
      "source": [
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqy74Fpo0jXi"
      },
      "source": [
        "### Fit Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yju2nvVNKVzp",
        "outputId": "837416b1-4493-4bb1-efe8-a8539b7dee6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model2.fit(train, validation_data=validation, epochs=5)\n",
        "model2.evaluate(validation)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "17/17 [==============================] - 92s 4s/step - loss: 0.3084 - accuracy: 0.8612 - val_loss: 4.8373 - val_accuracy: 0.6769\n",
            "Epoch 2/5\n",
            "17/17 [==============================] - 51s 3s/step - loss: 0.2241 - accuracy: 0.9193 - val_loss: 1.1828 - val_accuracy: 0.7692\n",
            "Epoch 3/5\n",
            "17/17 [==============================] - 51s 3s/step - loss: 0.1821 - accuracy: 0.9268 - val_loss: 0.5164 - val_accuracy: 0.8154\n",
            "Epoch 4/5\n",
            "17/17 [==============================] - 51s 3s/step - loss: 0.1638 - accuracy: 0.9418 - val_loss: 2.3939 - val_accuracy: 0.4308\n",
            "Epoch 5/5\n",
            "17/17 [==============================] - 51s 3s/step - loss: 0.1578 - accuracy: 0.9400 - val_loss: 0.4072 - val_accuracy: 0.8205\n",
            "7/7 [==============================] - 4s 451ms/step - loss: 0.4072 - accuracy: 0.8205\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40719708800315857, 0.8205128312110901]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}